{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23da95bf",
   "metadata": {},
   "source": [
    "# Car Price Prediction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956380f2",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "path = 'new_car_data.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c40e02",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b42bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car_age'] = 2024 - df['model_year']\n",
    "df.drop(columns=['ext_col'], inplace=True, axis=1)\n",
    "df['age_mileage_interaction'] = df['car_age'] * df['milage']\n",
    "df['avg_hp_by_year'] = df.groupby('model_year')['engin_hp'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017e3a2",
   "metadata": {},
   "source": [
    "### Mileage Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc57451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model_milage_avg'] = df.groupby('model')['milage'].transform('mean')\n",
    "df['milage_minus_model_avg'] = df['milage'] - df['model_milage_avg']\n",
    "df['milage_percentile'] = df['milage'].rank(pct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4777cc1",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(df.isna().sum())\n",
    "X = df.drop(columns=['price'], axis=1)\n",
    "y = df['price']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=42, random_state=42)\n",
    "df.info()\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6bc02",
   "metadata": {},
   "source": [
    "## Baseline Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946625fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def check_all_models(x_train, x_test, y_train, y_test):\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "        'Decision Tree': DecisionTreeRegressor(),\n",
    "        'Random Forest': RandomForestRegressor(),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(),\n",
    "        'AdaBoost': AdaBoostRegressor(),\n",
    "        'XGBoost': XGBRegressor(),\n",
    "        'XGB Random Forest': XGBRFRegressor(),\n",
    "    }\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(x_train, y_train)\n",
    "        preds = model.predict(x_test)\n",
    "        train_r2 = model.score(x_train, y_train)\n",
    "        test_r2  = model.score(x_test, y_test)\n",
    "        mae      = mean_absolute_error(y_test, preds)\n",
    "        mse      = mean_squared_error(y_test, preds)\n",
    "        rmse     = np.sqrt(mse)\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Train R²': train_r2,\n",
    "            'Test R²': test_r2,\n",
    "            'MAE': mae,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'Overfitting': test_r2 < train_r2,\n",
    "            'Underfitting': train_r2 < 0.5 and test_r2 < 0.5\n",
    "        })\n",
    "    display(pd.DataFrame(results))\n",
    "\n",
    "check_all_models(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d660f8",
   "metadata": {},
   "source": [
    "## XGBoost Quick Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    early_stopping_rounds=50,\n",
    "    n_estimators=1000,\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)\n",
    "print(model.best_iteration)\n",
    "print(model.best_score)\n",
    "print(model.score(x_test, y_test))\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "params = model.get_xgb_params()\n",
    "cv_results = xgb.cv(params, dtrain, num_boost_round=1000, nfold=5, metrics=('rmse',), early_stopping_rounds=50, as_pandas=True, seed=42)\n",
    "len(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee87238",
   "metadata": {},
   "source": [
    "## Optuna Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 2000),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        'min_child_weight': trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        'gamma': trial.suggest_float(\"gamma\", 0, 0.5),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'rmse',\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "    m = XGBRegressor(**params)\n",
    "    m.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)\n",
    "    preds = m.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=500, n_jobs=-1)\n",
    "print(study.best_value)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e4743",
   "metadata": {},
   "source": [
    "## Final Model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cf19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "best_model = XGBRegressor(\n",
    "    **study.best_params,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)\n",
    "train_preds = best_model.predict(x_train)\n",
    "test_preds  = best_model.predict(x_test)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "test_rmse  = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "train_r2   = r2_score(y_train, train_preds)\n",
    "test_r2    = r2_score(y_test, test_preds)\n",
    "print(train_rmse)\n",
    "print(test_rmse)\n",
    "print(train_r2)\n",
    "print(test_r2)\n",
    "explainer = shap.Explainer(best_model)\n",
    "shap_values = explainer(x_test)\n",
    "shap.summary_plot(shap_values, x_test)\n",
    "plt.scatter(y_test, test_preds, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.show()\n",
    "joblib.dump(best_model, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1108bdfd",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Load the saved model\n",
    "- Integrate into a web API\n",
    "- Deploy to production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76418feb",
   "metadata": {},
   "source": [
    "## Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa267e0f",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook execution finished\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
